{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfe9c09b",
   "metadata": {},
   "source": [
    "This notebook uses gdown to download files.\n",
    "You can download it with `pip install gdown`.\n",
    "Alternatively, you can download zip files manually and then run the other commands (or download everything from [this folder](https://drive.google.com/drive/folders/1e9cEAuQsLABU5SOkQF982Pw09wPIJbn7?usp=sharing))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3271d9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from imodels.util.dta_util import get_openml_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-report",
   "metadata": {},
   "source": [
    "# credit card default\n",
    "https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "affected-stream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  UCI_Credit_Card.zip\n",
      "  inflating: UCI_Credit_Card.csv     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1yff8lGjjBOUB_-M4FJOolXgnBX_akfiZ\n",
      "To: /Volumes/GoogleDrive/My Drive/research/rules/imodels/experiments/UCI_Credit_Card.zip\n",
      "100%|██████████| 1.00M/1.00M [00:00<00:00, 28.3MB/s]\n",
      "mkdir: data/credit_card: File exists\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "gdown 'https://drive.google.com/uc?id=1yff8lGjjBOUB_-M4FJOolXgnBX_akfiZ'\n",
    "unzip UCI_Credit_Card.zip\n",
    "rm UCI_Credit_Card.zip\n",
    "mkdir data/credit_card\n",
    "mv UCI_Credit_Card.csv data/credit_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "interesting-mechanics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"data/credit_card/UCI_Credit_Card.csv\")\n",
    "\n",
    "df_raw.columns = [col.lower() for col in df_raw.columns]\n",
    "orig_feature_count = len(df_raw.columns) - 2\n",
    "orig_feature_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "union-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['sex', 'education', 'marriage']\n",
    "df_enc = pd.get_dummies(df_raw, columns=categorical_features, prefix_sep=':')\n",
    "X, y = df_enc.drop(['id', 'default.payment.next.month'], axis=1), df_enc['default.payment.next.month']\n",
    "df_tgt_last = pd.concat((X, y), axis=1)\n",
    "df_tgt_last.to_csv(\"data/credit_card/credit_card_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-benjamin",
   "metadata": {},
   "source": [
    "# recidivism\n",
    "https://github.com/propublica/compas-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "jewish-expert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'compas-analysis'...\n",
      "remote: Enumerating objects: 31, done.\u001B[K\n",
      "remote: Total 31 (delta 0), reused 0 (delta 0), pack-reused 31\u001B[K\n",
      "Receiving objects: 100% (31/31), 15.24 MiB | 11.06 MiB/s, done.\n",
      "Resolving deltas: 100% (14/14), done.\n"
     ]
    }
   ],
   "source": [
    "!git -C data clone https://github.com/propublica/compas-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "secondary-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"data/compas-analysis/compas-scores-two-years.csv\")\n",
    "df_raw['c_jail_time'] = (pd.to_datetime(df_raw['c_jail_out']) - pd.to_datetime(df_raw['c_jail_in'])).dt.days\n",
    "cols_interest = ['id', 'age', 'c_charge_degree', 'race', 'age_cat', 'sex', \n",
    "                 'priors_count', 'days_b_screening_arrest', 'is_recid', \n",
    "                 'c_jail_in', 'c_jail_out', 'c_jail_time',\n",
    "                 'juv_fel_count', 'juv_other_count', 'juv_misd_count']\n",
    "df = df_raw[cols_interest]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-prior",
   "metadata": {},
   "source": [
    "### follow same filtering process as propublica analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "strong-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['is_recid'] != -1]\n",
    "df = df[df['c_charge_degree'] != 'O']\n",
    "df = df[df['days_b_screening_arrest'].abs() <= 30]\n",
    "df = df.drop(['c_jail_in', 'c_jail_out'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "exciting-carolina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_feature_count = len(df.columns) - 1\n",
    "orig_feature_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mexican-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc = pd.get_dummies(df, prefix_sep=':')\n",
    "df_enc.columns = df_enc.columns.str.replace(' ', '_')\n",
    "X, y = df_enc.drop(['id', 'is_recid'], axis=1), df_enc['is_recid']\n",
    "\n",
    "df_tgt_last = pd.concat((X, y), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "right-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tgt_last.to_csv('data/compas-analysis/compas_two_year_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-boxing",
   "metadata": {},
   "source": [
    "# juvenile \n",
    "https://www.icpsr.umich.edu/web/NACJD/studies/3986"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "congressional-panel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ICPSR_03986.zip\n",
      "   creating: ICPSR_03986/\n",
      "  inflating: ICPSR_03986/.DS_Store   \n",
      "  inflating: ICPSR_03986/03986-manifest.txt  \n",
      "   creating: ICPSR_03986/DS0001/\n",
      "  inflating: ICPSR_03986/DS0001/03986-0001-User_guide.pdf  \n",
      "   creating: ICPSR_03986/DS0001/03986-0001-Codebook/\n",
      "  inflating: ICPSR_03986/DS0001/03986-0001-Codebook/Questionnaire.pdf  \n",
      "  inflating: ICPSR_03986/DS0001/03986-0001-Data.txt  \n",
      "  inflating: ICPSR_03986/03986-descriptioncitation.html  \n",
      "  inflating: ICPSR_03986/03986-related_literature.txt  \n",
      "  inflating: ICPSR_03986/TermsOfUse.html  \n",
      "  inflating: ICPSR_03986/DS0001/feature_info.csv  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1wEFXutadmevTt1PUpjaDv4XH9KkSMdbx\n",
      "To: /Volumes/GoogleDrive/My Drive/research/rules/imodels/experiments/ICPSR_03986.zip\n",
      "100%|██████████| 2.42M/2.42M [00:00<00:00, 25.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gdown 'https://drive.google.com/uc?id=1wEFXutadmevTt1PUpjaDv4XH9KkSMdbx'\n",
    "unzip ICPSR_03986.zip\n",
    "rm ICPSR_03986.zip\n",
    "mv ICPSR_03986 data/ICPSR_03986"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-player",
   "metadata": {},
   "source": [
    "### create df from raw txt data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "enabling-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_rows = open('data/ICPSR_03986/DS0001/03986-0001-Data.txt').read().split('\\n')\n",
    "\n",
    "# consolidated info from 03986-0001-Codebook/Questionnaire.pdf and 03986-0001-User_guide.pdf\n",
    "metadata = pd.read_csv('data/ICPSR_03986/DS0001/feature_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "golden-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [[] for _ in range(len(raw_rows) - 1)]\n",
    "\n",
    "for i in range(len(rows)):\n",
    "    for j, l in zip(metadata['start_ind'], metadata['length']):\n",
    "        rows[i].append(raw_rows[i][j:j+l])\n",
    "\n",
    "for i in range(len(rows)):\n",
    "    rows[i] = list(map(lambda x: x.strip(), rows[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "intended-decision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4023, 280)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(rows)\n",
    "df.columns = metadata['feature_name'].values\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-standing",
   "metadata": {},
   "source": [
    "### clean missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "blessed-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['missing_vals_set'] = metadata['missing_val'].astype(str) + ' ' + metadata['missing_val_2'].astype(str)\n",
    "metadata['missing_vals_set'] += ' ' + metadata['missing_val_3'].astype(str)\n",
    "metadata['missing_vals_set'] = (\n",
    "    metadata['missing_vals_set'].apply(lambda x: set([v[:-2] for v in x.split(' ') if v != 'nan']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "tribal-translation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4023, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[:, ~metadata['over_10_percent_missing'].values]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adverse-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_col_missing_val_sets = metadata[~metadata['over_10_percent_missing']]['missing_vals_set']\n",
    "for i in range(df.shape[1]):\n",
    "    curr_feat_missing_values = rem_col_missing_val_sets.iloc[i]\n",
    "    df = df[~df.iloc[:, i].isin(curr_feat_missing_values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-affiliation",
   "metadata": {},
   "source": [
    "### separate outcome variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "attempted-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_variables = metadata['feature_name'][\n",
    "    metadata['delinquent_behavior'].astype(bool) & metadata['feature_name'].isin(df.columns)\n",
    "]\n",
    "drop_variables = list(outcome_variables) + ['id', 'any_deviance']\n",
    "X_cat, y = df.drop(drop_variables, axis=1), df['any_deviance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dimensional-serum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_feature_count = len(X_cat.columns)\n",
    "orig_feature_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-tissue",
   "metadata": {},
   "source": [
    "### encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "desirable-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = metadata['feature_name'][\n",
    "    metadata['categorical'].astype(bool) & metadata['feature_name'].isin(X_cat.columns)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "honest-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X_cat, columns=categorical_features, prefix_sep=':').astype('float32')\n",
    "y = y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "twelve-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.concat([X, y], axis=1)\n",
    "df_clean.to_csv('data/ICPSR_03986/DS0001/juvenile_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-internet",
   "metadata": {},
   "source": [
    "# diabetes readmission\n",
    "https://archive.ics.uci.edu/ml/datasets/diabetes+130-us+hospitals+for+years+1999-2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "according-estate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  readmission.zip\n",
      "   creating: readmission/\n",
      "  inflating: readmission/diabetic_data.csv  \n",
      "  inflating: readmission/description.pdf  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1rOoEbLjMYsyamKeq4WFwHNdSZXPcRQUH\n",
      "To: /Volumes/GoogleDrive/My Drive/research/rules/imodels/experiments/readmission.zip\n",
      "100%|██████████| 4.48M/4.48M [00:00<00:00, 60.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gdown 'https://drive.google.com/uc?id=1rOoEbLjMYsyamKeq4WFwHNdSZXPcRQUH'\n",
    "unzip readmission.zip\n",
    "rm readmission.zip\n",
    "mv readmission data/readmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "impossible-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/readmission/diabetic_data.csv')\n",
    "df = df.replace({'?': np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-halloween",
   "metadata": {},
   "source": [
    "### target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ranking-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['readmitted'] = df['readmitted'].replace({'NO': 0, '>30': 1, '<30': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-happiness",
   "metadata": {},
   "source": [
    "### race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "exact-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['race'] = df['race'].replace({np.nan: 'Other'})\n",
    "df = pd.get_dummies(df, columns=['race'], prefix_sep=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-transaction",
   "metadata": {},
   "source": [
    "### gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "incorrect-vampire",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['gender'] != 'Unknown/Invalid']\n",
    "df = pd.get_dummies(df, columns=['gender'], prefix_sep=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-premium",
   "metadata": {},
   "source": [
    "### age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "parallel-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df['age'].replace({\"[70-80)\":\"70+\",\n",
    "                               \"[60-70)\":\"[50-70)\",\n",
    "                               \"[50-60)\":\"[50-70)\",\n",
    "                               \"[80-90)\":\"70+\",\n",
    "                               \"[40-50)\":\"[20-50)\",\n",
    "                               \"[30-40)\":\"[20-50)\",\n",
    "                               \"[90-100)\":\"70+\",\n",
    "                               \"[20-30)\":\"[20-50)\"})\n",
    "df = pd.get_dummies(df, columns=['age'], prefix_sep=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-lithuania",
   "metadata": {},
   "source": [
    "### admission type id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ruled-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['admission_type_id'] = df['admission_type_id'].replace({1.0:\"Emergency\",\n",
    "                                                           2.0:\"Emergency\",\n",
    "                                                           3.0:\"Elective\",\n",
    "                                                           4.0:\"New Born\",\n",
    "                                                           5.0:np.nan,\n",
    "                                                           6.0:np.nan,\n",
    "                                                           7.0:\"Trauma Center\",\n",
    "                                                           8.0:np.nan})\n",
    "df = pd.get_dummies(df, columns=['admission_type_id'], prefix_sep=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-pixel",
   "metadata": {},
   "source": [
    "### discharge disposition ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "representative-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace(\n",
    "    {1:\"Discharged to Home\",\n",
    "     6:\"Discharged to Home\",\n",
    "     8:\"Discharged to Home\",\n",
    "     13:\"Discharged to Home\",\n",
    "     19:\"Discharged to Home\",\n",
    "     18:np.nan, 25:np.nan, 26:np.nan,\n",
    "     2:\"Other\", 3:\"Other\", 4:\"Other\",\n",
    "     5:\"Other\", 7:\"Other\", 9:\"Other\",\n",
    "     10:\"Other\", 11:\"Other\", 12:\"Other\",\n",
    "     14:\"Other\", 15:\"Other\", 16:\"Other\",\n",
    "     17:\"Other\", 20:\"Other\", 21:\"Other\",\n",
    "     22:\"Other\", 23:\"Other\", 24:\"Other\",\n",
    "     27:\"Other\", 28:\"Other\", 29:\"Other\", 30:\"Other\"}\n",
    ") \n",
    "df = pd.get_dummies(df, columns=['discharge_disposition_id'], prefix_sep=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-patent",
   "metadata": {},
   "source": [
    "### admission source ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "rotary-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['admission_source_id'] = df['admission_source_id'].replace(\n",
    "    {1:\"Referral\", 2:\"Referral\", 3:\"Referral\", 4:\"Transfer\",\n",
    "     5:\"Transfer\", 6:\"Transfer\", 7:\"Emergency\", 8:\"Other\",\n",
    "     9:\"Other\", 10:\"Transfer\", 11:\"Other\", 12:\"Other\",\n",
    "     13:\"Other\", 14:\"Other\", 15:np.nan, 17:np.nan, \n",
    "     18:\"Transfer\", 19:\"Other\", 20:np.nan, 21:np.nan,\n",
    "     22:\"Transfer\", 23:\"Other\", 24: \"Other\", 25:\"Transfer\",\n",
    "     26: \"Transfer\"}\n",
    ")\n",
    "df = pd.get_dummies(df, columns=['admission_source_id'], prefix_sep=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-planning",
   "metadata": {},
   "source": [
    "### medical specialty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "gorgeous-ebony",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['medical_specialty'] = df['medical_specialty'].replace(\n",
    "    {\"Orthopedics-Reconstructive\": \"Orthopedics\",\n",
    "     \"Surgeon\": \"Surgery-General\",\n",
    "     \"Surgery-Cardiovascular\": \"Surgery-Cardiovascular/Thoracic\",\n",
    "     \"Surgery-Thoracic\": \"Surgery-Cardiovascular/Thoracic\",\n",
    "     \"Pediatrics-Endocrinology\": \"Pediatrics\",\n",
    "     \"Pediatrics-CriticalCare\": \"Pediatrics\",\n",
    "     \"Pediatrics-Pulmonology\": \"Pediatrics\",\n",
    "     \"Radiologist\": \"Radiology\",\n",
    "     \"Oncology\": \"Hematology/Oncology\",\n",
    "     \"Hematology\": \"Hematology/Oncology\",\n",
    "     \"Gynecology\": \"ObstetricsandGynecology\",\n",
    "     \"Obstetrics\": \"ObstetricsandGynecology\"\n",
    "     }\n",
    ")\n",
    "df['medical_specialty'] = df['medical_specialty'].replace(\n",
    "    {spec: \"Other\" for spec in df['medical_specialty'].value_counts().index.values[15:]}\n",
    ")\n",
    "df = pd.get_dummies(df, columns=['medical_specialty'], prefix_sep=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-diving",
   "metadata": {},
   "source": [
    "### diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "unusual-progressive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_diagnosis(data, cols):\n",
    "    for col in cols:\n",
    "        data.loc[(data[col].str.contains(\"V\")) | (data[col].str.contains(\"E\")), col] = -1\n",
    "        data[col] = data[col].astype(np.float16)\n",
    "\n",
    "    for col in cols:\n",
    "        data[\"temp_diag\"] = np.nan\n",
    "        data.loc[(data[col]>=390) & (data[col]<=459) | (data[col]==785), \"temp_diag\"] = \"Circulatory\"\n",
    "        data.loc[(data[col]>=460) & (data[col]<=519) | (data[col]==786), \"temp_diag\"] = \"Respiratory\"\n",
    "        data.loc[(data[col]>=520) & (data[col]<=579) | (data[col]==787), \"temp_diag\"] = \"Digestive\"\n",
    "        data.loc[(data[col]>=680) & (data[col]<=709) | (data[col]==782), \"temp_diag\"] = \"Skin\"\n",
    "        data.loc[(data[col]>=240) & (data[col]<250) | (data[col]>251) & (data[col]<=279), \"temp_diag\"] = \"Non-diabetes endocrine/metabolic\"\n",
    "        data.loc[(data[col]>=250) & (data[col]<251), \"temp_diag\"] = \"Diabetes\"\n",
    "        data.loc[(data[col]>=800) & (data[col]<=999), \"temp_diag\"] = \"Injury\"\n",
    "        data.loc[(data[col]>=710) & (data[col]<=739), \"temp_diag\"] = \"Musculoskeletal\"\n",
    "        data.loc[(data[col]>=580) & (data[col]<=629) | (data[col] == 788), \"temp_diag\"] = \"Genitourinary\"\n",
    "        data.loc[(data[col]>=140) & (data[col]<=239), \"temp_diag\"] = \"Neoplasms\"\n",
    "        data.loc[(data[col]>=290) & (data[col]<=319), \"temp_diag\"] = \"Mental\"\n",
    "        data.loc[(data[col]>=1) & (data[col]<=139), \"temp_diag\"] = \"Infectious\"\n",
    "\n",
    "        data[\"temp_diag\"] = data[\"temp_diag\"].fillna(\"Other\")\n",
    "        data[col] = data[\"temp_diag\"]\n",
    "        data = data.drop(\"temp_diag\", axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "wired-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = map_diagnosis(df, [\"diag_1\",\"diag_2\",\"diag_3\"])\n",
    "df = pd.get_dummies(df, columns=[\"diag_1\",\"diag_2\",\"diag_3\"], prefix_sep=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-sampling",
   "metadata": {},
   "source": [
    "### medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "sublime-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diabetesMed'] = df['diabetesMed'].replace({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "burning-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['change'] = df['change'].replace({'Ch': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "exciting-hierarchy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
       "       'glimepiride', 'glipizide', 'glyburide', 'pioglitazone',\n",
       "       'rosiglitazone', 'acarbose', 'miglitol', 'tolazamide', 'insulin',\n",
       "       'glyburide-metformin'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_meds = df.columns[14:37]\n",
    "keep_meds = all_meds.values[\n",
    "    [(df[med].value_counts().shape[0] > 1) and (df[med].value_counts()['Steady'] > 30) for med in all_meds]\n",
    "]\n",
    "drop_meds = all_meds.values[~all_meds.isin(keep_meds)]\n",
    "keep_meds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "successful-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=keep_meds, prefix_sep=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-railway",
   "metadata": {},
   "source": [
    "### test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "structured-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['A1Cresult', 'max_glu_serum'], prefix_sep=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-satin",
   "metadata": {},
   "source": [
    "### final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aggregate-westminster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_columns = ['encounter_id', 'patient_nbr', 'weight', 'payer_code'] + drop_meds.tolist()\n",
    "\n",
    "X, y = df.drop(drop_columns + ['readmitted'], axis=1), df['readmitted']\n",
    "df_clean = pd.concat([X, y], axis=1)\n",
    "df_clean.to_csv('data/readmission/readmission_clean.csv', index=False)\n",
    "\n",
    "orig_feature_count = len(pd.read_csv('data/readmission/diabetic_data.csv').columns) - len(drop_columns) - 1\n",
    "orig_feature_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-desktop",
   "metadata": {},
   "source": [
    "# breast cancer\n",
    "https://www.openml.org/d/13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "chubby-brook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_openml_dataset(13)\n",
    "df = df.dropna()\n",
    "\n",
    "categorical_features = ['menopause', 'breast-quad', 'deg-malig']\n",
    "df_enc = pd.get_dummies(df, columns=categorical_features)\n",
    "\n",
    "X, y = df_enc.drop('recurrence-events', axis=1), df_enc['recurrence-events']\n",
    "df_clean = pd.concat([X, y], axis=1)\n",
    "df_clean.to_csv('data/breast_cancer.csv', index=False)\n",
    "\n",
    "orig_feature_count = len(df.columns) - 1\n",
    "orig_feature_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-nerve",
   "metadata": {},
   "source": [
    "# german credit\n",
    "https://www.openml.org/d/31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "developing-batch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_openml_dataset(31)\n",
    "\n",
    "categorical_features = ['checking_status', 'credit_history', 'purpose', 'savings_status', 'employment', \n",
    "                        'personal_status', 'other_parties', 'property_magnitude', 'other_payment_plans',\n",
    "                        'housing', 'job', 'num_dependents']\n",
    "df_enc = pd.get_dummies(df, columns=categorical_features)\n",
    "\n",
    "X, y = df_enc.drop('good', axis=1), df_enc['good']\n",
    "df_clean = pd.concat([X, y], axis=1)\n",
    "df_clean.to_csv('data/credit_g.csv', index=False)\n",
    "\n",
    "orig_feature_count = len(df.columns) - 1\n",
    "orig_feature_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-badge",
   "metadata": {},
   "source": [
    "# haberman\n",
    "https://www.openml.org/d/43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "extensive-belize",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_openml_dataset(43)\n",
    "df.to_csv('data/haberman.csv', index=False)\n",
    "orig_feature_count = len(df.columns) - 1\n",
    "orig_feature_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-special",
   "metadata": {},
   "source": [
    "# heart\n",
    "https://www.openml.org/d/1574"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "trying-winner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_openml_dataset(1574)\n",
    "df = df.rename(columns={1.0:'target'})\n",
    "\n",
    "categorical_features = ['att_13']\n",
    "\n",
    "df_enc = pd.get_dummies(df, columns=categorical_features)\n",
    "\n",
    "for col in [f'att_{i}' for i in [2, 6, 7, 9, 11]]:\n",
    "    df_enc[col] = (df_enc[col] == 1.0).astype(int)\n",
    "\n",
    "X, y = df_enc.drop('target', axis=1), df_enc['target']\n",
    "df_clean = pd.concat([X, y], axis=1)\n",
    "df_clean.to_csv('data/heart.csv', index=False)\n",
    "\n",
    "orig_feature_count = len(df.columns) - 1\n",
    "orig_feature_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}